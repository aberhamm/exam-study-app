# ========================================
# SCXMCL Study Utility - Environment Variables
# ========================================
# Copy this file to .env.local and fill in your values
# Never commit .env.local or any file containing actual secrets

# ========================================
# Required Configuration
# ========================================

# --- Supabase Authentication ---
# Get these from your Supabase project dashboard: https://supabase.com/dashboard
NEXT_PUBLIC_SUPABASE_URL=your-supabase-project-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-supabase-service-role-key

# --- MongoDB Database ---
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB=study-util

# --- MongoDB Collections (defaults) ---
MONGODB_EXAMS_COLLECTION=exams
MONGODB_QUESTIONS_COLLECTION=questions
MONGODB_QUESTION_EMBEDDINGS_COLLECTION=question_embeddings
MONGODB_EXAM_COMPETENCIES_COLLECTION=exam_competencies

# ========================================
# AI Services Configuration
# ========================================

# --- OpenAI (for embeddings) ---
# Used when USE_PORTKEY is not enabled
OPENAI_API_KEY=your-openai-key
QUESTIONS_EMBEDDING_MODEL=text-embedding-3-small
QUESTIONS_EMBEDDING_DIMENSIONS=1536

# Alternative naming (also supported)
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSIONS=1536

# --- OpenRouter (for chat completions) ---
# Used when USE_PORTKEY is not enabled
OPENROUTER_API_KEY=your-openrouter-key
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# --- Portkey (routes all LLM calls through Portkey when enabled) ---
# Model Catalog: For PUBLIC Portkey (api.portkey.ai), use "@provider/model" format
# Enterprise/Custom Gateways: May require plain model names or provider/model format (no @)
USE_PORTKEY=false
PORTKEY_API_KEY=pk_live_********************************
PORTKEY_BASE_URL=https://api.portkey.ai/v1
# For enterprise gateways, sets the x-portkey-provider header automatically
# Example: @aws-bedrock-use2
PORTKEY_PROVIDER=
# Optional defaults
PORTKEY_MODEL=@anthropic/claude-3.5-sonnet
# Task-specific defaults (optional)
PORTKEY_MODEL_CHAT=@anthropic/claude-3.5-sonnet
PORTKEY_MODEL_EXPLANATION=@anthropic/claude-3.5-sonnet
PORTKEY_MODEL_QUESTION_GENERATION=@google/gemini-2.0-flash
PORTKEY_MODEL_EMBEDDINGS=@openai/text-embedding-3-small
# Custom headers (key:value pairs separated by literal \n). API key header is added automatically.
# Example:
# PORTKEY_CUSTOM_HEADERS=x-portkey-provider:@aws-bedrock-use2\nx-trace-id:study-util-local
PORTKEY_CUSTOM_HEADERS=
# If you use an enterprise or Bedrock gateway, update the models accordingly:
# PORTKEY_PROVIDER=@aws-bedrock-use2
# PORTKEY_MODEL_EXPLANATION=us.anthropic.claude-sonnet-4-20250514-v1:0
# PORTKEY_MODEL_CHAT=us.anthropic.claude-sonnet-4-20250514-v1:0
# PORTKEY_MODEL_EMBEDDINGS=amazon.titan-embed-text-v1  # 1536 dims (compatible with current DB)
# PORTKEY_MODEL_EMBEDDINGS=amazon.titan-embed-text-v2:0  # 1024 dims (requires re-embedding)

# ========================================
# Application Settings
# ========================================

# Node environment
NODE_ENV=development

# Application URLs
NEXT_PUBLIC_BASE_URL=http://localhost:3000
SITE_URL=http://localhost:3000
NEXT_PUBLIC_SITE_URL=http://localhost:3000

# ========================================
# Feature Flags
# ========================================

# Debug retrieval/embedding steps (verbose logging)
DEBUG_RETRIEVAL=false
NEXT_PUBLIC_DEBUG_RETRIEVAL=false

# Use random sort sampling instead of $sample for question preparation
# Can perform better on some MongoDB clusters
USE_RAND_SORT_SAMPLING=false

# ========================================
# Session Configuration
# ========================================

# Session max age in seconds (default: 28800 = 8 hours)
# Special values: "never" or "0" = never expires (30 years)
SESSION_MAX_AGE=28800

# Session update age in seconds (how often to update session activity)
# Default: 3600 (1 hour)
SESSION_UPDATE_AGE=3600

# ========================================
# Vector Search & Retrieval Configuration
# ========================================

# Vector index names (optional - defaults provided)
MONGODB_QUESTION_EMBEDDINGS_VECTOR_INDEX=question_embeddings_vector_index
MONGODB_COMPETENCIES_VECTOR_INDEX=competencies_vector_index
MONGODB_DOCUMENT_EMBEDDINGS_VECTOR_INDEX=embedding_vector

# Vector search parameters
CANDIDATE_MULTIPLIER=10
MAX_CANDIDATES=100
MAX_CONTEXT_CHUNKS=4
MAX_CHUNK_CHARS=1500

# API timeouts and retries
API_TIMEOUT_MS=30000
MAX_RETRIES=3

# ========================================
# Notes
# ========================================
#
# 1. Portkey Integration:
#    - When USE_PORTKEY=true, set PORTKEY_API_KEY
#    - All LLM calls (embeddings + chat) will route through Portkey
#    - You can keep your provider keys inside Portkey; no virtual key needed
#    - OPENAI_API_KEY and OPENROUTER_API_KEY are not required when USE_PORTKEY=true
#
# 2. MongoDB Atlas:
#    - Use SRV connection string: mongodb+srv://user:pass@cluster.mongodb.net
#    - Ensure your IP is allow-listed in Atlas network access settings
#
# 3. Vector Search:
#    - Requires MongoDB Atlas with vector search enabled
#    - Create vector indexes with cosine similarity matching your embedding dimensions
#    - See scripts/create-vector-index.ts for index creation
#
# 4. Authentication:
#    - Supabase handles all user authentication via magic-link (OTP) sign-in
#    - Ensure all allowed users already exist in Supabase with the proper claims
#    - Admin access is managed via custom claims in Supabase
#    - Run supabase-schema.sql in your Supabase SQL Editor
#
# 5. Embeddings:
#    - Can use OpenAI directly or route through Portkey
#    - Model default: text-embedding-3-small
#    - Dimensions default: 1536
#
# 6. Chat Completions:
#    - Can use OpenRouter directly or route through Portkey
#    - Used for question explanation generation
#    - Model default: anthropic/claude-3.5-sonnet (OpenRouter) or gpt-4o-mini (Portkey)
